{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6cd9a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e10fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir= r'C:\\Users\\maver\\OneDrive\\Documents\\Giridhar\\sem5\\information security CSE3501\\ISAJCOMP\\output'\n",
    "train_path = r'C:\\Users\\maver\\OneDrive\\Documents\\Giridhar\\sem5\\information security CSE3501\\ISAJCOMP\\output\\train'\n",
    "val_path = r'C:\\Users\\maver\\OneDrive\\Documents\\Giridhar\\sem5\\information security CSE3501\\ISAJCOMP\\output\\val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf623eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "\n",
    "for folder in os.listdir(train_path):\n",
    "\n",
    "    sub_path=train_path+\"\\\\\"+folder\n",
    "\n",
    "    for img in os.listdir(sub_path):\n",
    "\n",
    "        image_path=sub_path+\"\\\\\"+img\n",
    "\n",
    "        img_arr=cv2.imread(image_path)\n",
    "\n",
    "        img_arr=cv2.resize(img_arr,(64,64))\n",
    "\n",
    "        x_train.append(img_arr)\n",
    "x_val=[]\n",
    "\n",
    "for folder in os.listdir(val_path):\n",
    "\n",
    "    sub_path=val_path+\"\\\\\"+folder\n",
    "\n",
    "    for img in os.listdir(sub_path):\n",
    "\n",
    "        image_path=sub_path+\"\\\\\"+img\n",
    "\n",
    "        img_arr=cv2.imread(image_path)\n",
    "\n",
    "        img_arr=cv2.resize(img_arr,(64,64))\n",
    "\n",
    "        x_val.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "360e1d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.array(x_train)\n",
    "val_x=np.array(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc464192",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_x/255.0\n",
    "val_x=val_x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5d5ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b0b1f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4809 images belonging to 2 classes.\n",
      "Found 1203 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'sparse')\n",
    "val_set = val_datagen.flow_from_directory(val_path,\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99c0357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=training_set.classes\n",
    "val_y=val_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d5547c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'benign': 0, 'malware': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d84eb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4809, 64, 64, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44494194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 32)        60032     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 40, 40, 32)        640032    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 20, 20, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 20, 20, 32)        173088    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 32)          173088    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,572,577\n",
      "Trainable params: 1,572,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,(25,25),padding = 'same',input_shape=train_x[0].shape))\n",
    "model.add(Conv2D(32,(25,25),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(32,(13,13),padding = 'same',activation='relu'))\n",
    "model.add(Conv2D(32,(13,13),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['binary_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb9b6065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 59s 2s/step - loss: 1.2722 - binary_accuracy: 0.4995\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6967 - binary_accuracy: 0.5546\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6567 - binary_accuracy: 0.5693\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6946 - binary_accuracy: 0.5619\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6591 - binary_accuracy: 0.5577\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6451 - binary_accuracy: 0.6076\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6349 - binary_accuracy: 0.6933\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.6245 - binary_accuracy: 0.6554\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.6047 - binary_accuracy: 0.7135\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.5986 - binary_accuracy: 0.6690\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.5858 - binary_accuracy: 0.7517\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.6496 - binary_accuracy: 0.6180\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.5988 - binary_accuracy: 0.6779\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.5837 - binary_accuracy: 0.7268\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.5587 - binary_accuracy: 0.7862\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.5431 - binary_accuracy: 0.7833\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.5374 - binary_accuracy: 0.7694\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.5222 - binary_accuracy: 0.7935\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.5074 - binary_accuracy: 0.8010\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.5473 - binary_accuracy: 0.7282\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.5077 - binary_accuracy: 0.7929\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.5231 - binary_accuracy: 0.7513\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.5186 - binary_accuracy: 0.7613\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4932 - binary_accuracy: 0.7894\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4991 - binary_accuracy: 0.7894\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4845 - binary_accuracy: 0.7937\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4703 - binary_accuracy: 0.8083\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4747 - binary_accuracy: 0.7819\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4603 - binary_accuracy: 0.8120\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4431 - binary_accuracy: 0.8174\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4191 - binary_accuracy: 0.8336\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4113 - binary_accuracy: 0.8357\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4448 - binary_accuracy: 0.7894\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4633 - binary_accuracy: 0.7889\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4135 - binary_accuracy: 0.8266\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3851 - binary_accuracy: 0.8436\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3656 - binary_accuracy: 0.8488\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3547 - binary_accuracy: 0.8519\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3594 - binary_accuracy: 0.8557\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3627 - binary_accuracy: 0.8490\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3404 - binary_accuracy: 0.8623\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3256 - binary_accuracy: 0.8665\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3184 - binary_accuracy: 0.8711\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3123 - binary_accuracy: 0.8734\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3208 - binary_accuracy: 0.8717\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2972 - binary_accuracy: 0.8798\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2921 - binary_accuracy: 0.8863\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2989 - binary_accuracy: 0.8779\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2900 - binary_accuracy: 0.8871\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2839 - binary_accuracy: 0.8894\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2627 - binary_accuracy: 0.9004\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3084 - binary_accuracy: 0.8734\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2644 - binary_accuracy: 0.8987\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2803 - binary_accuracy: 0.8906\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2504 - binary_accuracy: 0.9008\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2446 - binary_accuracy: 0.9048\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2338 - binary_accuracy: 0.9079\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2343 - binary_accuracy: 0.9087\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2378 - binary_accuracy: 0.9093\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2186 - binary_accuracy: 0.9185\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2223 - binary_accuracy: 0.9156\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2102 - binary_accuracy: 0.9191\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2092 - binary_accuracy: 0.9197\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2116 - binary_accuracy: 0.9191\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2017 - binary_accuracy: 0.9247\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1916 - binary_accuracy: 0.9270\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1783 - binary_accuracy: 0.9308\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1897 - binary_accuracy: 0.9270\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2122 - binary_accuracy: 0.9141\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1919 - binary_accuracy: 0.9322\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1770 - binary_accuracy: 0.9324\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2050 - binary_accuracy: 0.9191\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1949 - binary_accuracy: 0.9218\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1717 - binary_accuracy: 0.9353\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1684 - binary_accuracy: 0.9372\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1667 - binary_accuracy: 0.9333\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1466 - binary_accuracy: 0.9457\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1455 - binary_accuracy: 0.9455\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1473 - binary_accuracy: 0.9432\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1352 - binary_accuracy: 0.9499\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1294 - binary_accuracy: 0.9511\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1261 - binary_accuracy: 0.9549\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2142 - binary_accuracy: 0.9145\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1497 - binary_accuracy: 0.9409\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1386 - binary_accuracy: 0.9464\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1551 - binary_accuracy: 0.9391\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1982 - binary_accuracy: 0.9181\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2407 - binary_accuracy: 0.9218\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1578 - binary_accuracy: 0.9387\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1312 - binary_accuracy: 0.9503\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1245 - binary_accuracy: 0.9547\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1245 - binary_accuracy: 0.9553\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1166 - binary_accuracy: 0.9565\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1584 - binary_accuracy: 0.9330\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1433 - binary_accuracy: 0.9455\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1379 - binary_accuracy: 0.9445\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1347 - binary_accuracy: 0.9478\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1449 - binary_accuracy: 0.9430\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1275 - binary_accuracy: 0.9495\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1210 - binary_accuracy: 0.9576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bcaa07a608>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y,\n",
    "              batch_size = 512,\n",
    "              epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f0170eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='model.png',\n",
    "    show_shapes=False,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c10d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Dynamic.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ec4f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model('Dynamic.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cd909ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26b5bafa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 4s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc0f5d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in y_pred:\n",
    "    if i[0]>0.5:\n",
    "        result.append(1)\n",
    "    else:\n",
    "        result.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f48acc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f3234a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "389fd92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77c96aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('abc',val_x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf45daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from PIL import Image\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "path_new = r'C:\\Users\\maver\\OneDrive\\Documents\\Giridhar\\sem5\\information security CSE3501\\ISAJCOMP\\New folder'\n",
    "\n",
    "h = 256 #height of image\n",
    "w = 256 #width of image\n",
    "\n",
    "#be careful with using this function, it will consume memory, access to disk and time\n",
    "images = []\n",
    "for f in listdir(path_new):\n",
    "  with open(os.path.join(path_new, f), 'rb') as img_set:\n",
    "      img_arr = img_set.read(h*w)\n",
    "      while img_arr:\n",
    "          if len(img_arr) == h*w and img_arr not in images:\n",
    "              images.append(img_arr)\n",
    "          img_arr = img_set.read(h*w)\n",
    "\n",
    "#And you can save them into png files\n",
    "count = 0\n",
    "for img in images:\n",
    "    png = Image.fromarray(np.reshape(list(img), (h,w)).astype('float32'), mode='L')\n",
    "    png.save('image_l%d.png'%count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb8b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
